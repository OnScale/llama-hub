{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy Node Parser\n",
    "\n",
    "The `CodeHierarchyNodeParser` is useful to split long code files into more reasonable chunks. What this will do is create a \"Hierarchy\" of sorts, where sections of the code are made more reasonable by replacing the scope body with short comments telling the LLM to search for a referenced node if it wants to read that context body. This is called skeletonization, and is toggled by setting `skeleton` to `True` which it is by default. Nodes in this hierarchy will be split based on scope, like function, class, or method scope, and will have links to their children and parents so the LLM can traverse the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Import\n",
    "\n",
    "First be sure to install the necessary [tree-sitter](https://tree-sitter.github.io/tree-sitter/) libraries.\n",
    "\n",
    "`pip install tree-sitter tree-sitter-languages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser.code_hierarchy import CodeHierarchyNodeParser\n",
    "from llama_index.text_splitter import CodeSplitter\n",
    "from llama_index.readers import SimpleDirectoryReader\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def print_python(python_text):\n",
    "    \"\"\"This function prints python text in ipynb nicely formatted.\"\"\"\n",
    "    display(Markdown(\"```python\\n\"+python_text+\"```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, choose a directory you want to scan, and glob for all the code files you want to import.\n",
    "\n",
    "In this case I'm going to glob all \"*.py\" files in the `llama_index/node_parser` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[Path(\"../../../../llama_index/node_parser/code_hierarchy.py\")],\n",
    "    file_metadata=lambda x: {\"filepath\": x},\n",
    ")\n",
    "nodes = reader.load_data()\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the code hierarchy node parser itself. Lets have it parse itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 32984\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    start_signature_types: Optional[List[_SignatureCaptureType]] = Field(\n",
       "\n",
       "# ...```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Length of text: {len(nodes[0].text)}\")\n",
    "print_python(nodes[0].text[:1500]+\"\\n\\n# ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are we to do? Well lets try splitting it. We are going to use the `CodeHierarchyNodeParser` to split the nodes into more reasonable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes after splitting: 86\n"
     ]
    }
   ],
   "source": [
    "split_nodes = CodeHierarchyNodeParser(\n",
    "    language=\"python\",\n",
    "    # You can further parameterize the CodeSplitter to split the code\n",
    "    # into \"chunks\" that match your context window size using\n",
    "    # chunck_lines and max_chars parameters, here we just use the defaults\n",
    "    code_splitter=CodeSplitter(language=\"python\", max_chars=1000, chunk_lines=10),\n",
    ").get_nodes_from_documents(nodes)\n",
    "print(\"Number of nodes after splitting:\", len(split_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So that split up our data from 8 nodes into 112 nodes! Whats the max length of any of these nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest text in nodes: 1160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longest text in nodes: {max(len(n.text) for n in split_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much shorter than before! Let's look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 857be953-32d9-46f3-acdb-faaa20001b75\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id af1033f4-834f-4daa-9254-083cc851868c\n",
       "    # Code replaced for brevity. See node_id 9076fc5d-c9a6-42a1-a8fe-1ee5ee9492c0```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(split_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without even needing a long printout we can see everything this module imported in the first document (which is at the module level) and the single class it defines. However, now instead of the class body, we see a comment: \n",
    "\n",
    "`# Code replaced for brevity. See node_id {node_id}`\n",
    "\n",
    "What if we go to that node_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to print the node with UUID: 9076fc5d-c9a6-42a1-a8fe-1ee5ee9492c0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 0280460a-d023-4eb3-8a8c-d95a83011117\n",
       "\"\"\"\n",
       "Maps language -> Node Type -> SignatureCaptureOptions\n",
       "\n",
       "The best way for a developer to discover these is to put a breakpoint at the TIP\n",
       "tag in _chunk_node, and then create a unit test for some code, and then iterate\n",
       "through the code discovering the node names.\n",
       "\"\"\"\n",
       "    # Code replaced for brevity. See node_id c973e5ad-6305-4189-83f5-ff10823cdfbb```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_nodes_by_id = {n.node_id: n for n in split_nodes}\n",
    "uuid_from_text = split_nodes[0].text.splitlines()[-1].split(\" \")[-1]\n",
    "print(\"Going to print the node with UUID:\", uuid_from_text)\n",
    "print_python(split_nodes_by_id[uuid_from_text].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the relationships on this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='60a63ceb-3c0a-4eee-8ae1-7fdc14510edf', node_type=<ObjectType.TEXT: '1'>, metadata={'language': 'python', 'inclusive_scopes': [], 'filepath': '../../../../llama_index/node_parser/code_hierarchy.py'}, hash='9fa8b6ef0b523dabf7b1618041956504f6abd633b7d600c53250c8444a0fe906'),\n",
      " <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='60a63ceb-3c0a-4eee-8ae1-7fdc14510edf', node_type=<ObjectType.TEXT: '1'>, metadata={'language': 'python', 'inclusive_scopes': [], 'filepath': '../../../../llama_index/node_parser/code_hierarchy.py'}, hash='ae4500dea30a8e7958b560a7ddc7953adab1865453160af0870a8858b7187404'),\n",
      " <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='67278947-e13b-4dd3-bfb9-c0a319cbdd10', node_type=<ObjectType.TEXT: '1'>, metadata={'language': 'python', 'inclusive_scopes': [], 'filepath': '../../../../llama_index/node_parser/code_hierarchy.py'}, hash='02eb2776daa0b6b9e82333fc4a81327d73645eb26715b31ddcd3e1c4da597c9b'),\n",
      " <NodeRelationship.PARENT: '4'>: None,\n",
      " <NodeRelationship.CHILD: '5'>: [RelatedNodeInfo(node_id='9abb601e-ad00-4255-91f0-ccac99cfe818', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_SignatureCaptureType', 'type': 'class_definition', 'signature': 'class _SignatureCaptureType(BaseModel):'}]}, hash='5662e50d934f409c73ba7aab4721f06107efd2f70c96739535f1db03a110ebcb'),\n",
      "                                 RelatedNodeInfo(node_id='f930d82e-9749-4ee3-a8b2-82273c402162', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_SignatureCaptureOptions', 'type': 'class_definition', 'signature': 'class _SignatureCaptureOptions(BaseModel):'}]}, hash='f7b1002b090f702cac9472c91aefeca14e2af86fd018e7ad87e591713aa80061'),\n",
      "                                 RelatedNodeInfo(node_id='6f7ace8e-2328-48e8-bb55-48a9ab80565d', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_ScopeMethod', 'type': 'class_definition', 'signature': 'class _ScopeMethod(Enum):'}]}, hash='e39268b29dbc9718e74c8ac1bad4836a53be2dab852205bb50e55255d6fdf883'),\n",
      "                                 RelatedNodeInfo(node_id='663cf484-d00a-40e0-b6c3-1e7307be7596', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_CommentOptions', 'type': 'class_definition', 'signature': 'class _CommentOptions(BaseModel):'}]}, hash='517bb253215f78c0dc49bf27d5fe9203722aac9118f6f93df5e8acbc2263df32'),\n",
      "                                 RelatedNodeInfo(node_id='3536bd19-476e-475c-b30b-7402847c456f', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_ScopeItem', 'type': 'class_definition', 'signature': 'class _ScopeItem(BaseModel):'}]}, hash='9c6198a2f3a890cd501d7299bff4f9e26a4aea32d47bac2b58b5b5d636639774'),\n",
      "                                 RelatedNodeInfo(node_id='1606d7d6-71c8-44bd-88b5-ae1bb5ad6c49', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': '_ChunkNodeOutput', 'type': 'class_definition', 'signature': 'class _ChunkNodeOutput(BaseModel):'}]}, hash='fe8b59e23f80c626ad672f51001db9b3650193e156042f9cef3515bcb02a56c0'),\n",
      "                                 RelatedNodeInfo(node_id='31e61874-7ef5-40c8-9897-0ce2bd65c4ac', node_type=<ObjectType.TEXT: '1'>, metadata={'inclusive_scopes': [{'name': 'CodeHierarchyNodeParser', 'type': 'class_definition', 'signature': 'class CodeHierarchyNodeParser(NodeParser):'}]}, hash='66955e0f3d3bd7d01f24b5a9f0f7dd2020e3abd05b9d454f32ae44c6271e8241')]}\n"
     ]
    }
   ],
   "source": [
    "pprint(split_nodes_by_id[uuid_from_text].relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NEXT` `PREV` relationships come from the `CodeSplitter` which is a component of the `CodeHierarchyNodeParser`. It is responsible for cutting up the nodes into chunks that are a certain character length. For more information about the `CodeSplitter` read this:\n",
    "\n",
    "[Code Splitter](llama_index/docs/module_guides/loading/node_parsers/modules.md#CodeSplitter)\n",
    "\n",
    "The `PARENT` and `CHILD` relationships come from the `CodeHierarchyNodeParser` which is responsible for creating the hierarchy of nodes. Things like classes, functions, and methods are nodes in this hierarchy.\n",
    "\n",
    "The `SOURCE` is the original file that this node came from.\n",
    "\n",
    "For example, we can get the `NEXT` few nodes like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 9076fc5d-c9a6-42a1-a8fe-1ee5ee9492c0\n",
       "_DEFAULT_SIGNATURE_IDENTIFIERS: Dict[str, Dict[str, _SignatureCaptureOptions]] =\n",
       "    # Code replaced for brevity. See node_id 95dcf765-200b-4ac4-8efc-493f02153460```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id c973e5ad-6305-4189-83f5-ff10823cdfbb\n",
       "{\n",
       "    \"python\": {\n",
       "        \"function_definition\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"block\", inclusive=False)],\n",
       "            name_identifier=\"identifier\",\n",
       "        ),\n",
       "        \"class_definition\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"block\", inclusive=False)],\n",
       "            name_identifier=\"identifier\",\n",
       "        ),\n",
       "    },\n",
       "    \"html\": {\n",
       "        \"element\": _SignatureCaptureOptions(\n",
       "            start_signature_types=[_SignatureCaptureType(type=\"<\", inclusive=True)],\n",
       "            end_signature_types=[_SignatureCaptureType(type=\">\", inclusive=True)],\n",
       "            name_identifier=\"tag_name\",\n",
       "        )\n",
       "    },\n",
       "    # Code replaced for brevity. See node_id 54cf6a02-6771-4869-9273-5b87b991da04```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 95dcf765-200b-4ac4-8efc-493f02153460\n",
       "\"cpp\": {\n",
       "        \"class_specifier\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"type_identifier\",\n",
       "        ),\n",
       "        \"function_definition\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"function_declarator\",\n",
       "        ),\n",
       "    },\n",
       "    # Code replaced for brevity. See node_id 3c34fdb4-98e9-4db8-ba54-feeb05fed250```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 54cf6a02-6771-4869-9273-5b87b991da04\n",
       "\"typescript\":\n",
       "    # Code replaced for brevity. See node_id 1ab1abea-2410-4dd1-95a6-e869bea7a568```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 3c34fdb4-98e9-4db8-ba54-feeb05fed250\n",
       "{\n",
       "        \"interface_declaration\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"type_identifier\",\n",
       "        ),\n",
       "        \"lexical_declaration\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"identifier\",\n",
       "        ),\n",
       "        \"function_declaration\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"identifier\",\n",
       "        ),\n",
       "        \"class_declaration\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"type_identifier\",\n",
       "        ),\n",
       "        \"method_definition\": _SignatureCaptureOptions(\n",
       "            end_signature_types=[_SignatureCaptureType(type=\"{\", inclusive=False)],\n",
       "            name_identifier=\"property_identifier\",\n",
       "        ),\n",
       "    }\n",
       "    # Code replaced for brevity. See node_id 60b230cb-0085-473b-9099-cc185ad7d9a9```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.schema import NodeRelationship\n",
    "\n",
    "node_id = uuid_from_text\n",
    "for i in range(5):\n",
    "    if NodeRelationship.NEXT not in split_nodes_by_id[node_id].relationships:\n",
    "        print(\"No next node found!\")\n",
    "        break\n",
    "    next_node_relationship_info = split_nodes_by_id[node_id].relationships[\n",
    "        NodeRelationship.NEXT\n",
    "    ]\n",
    "    next_node = split_nodes_by_id[next_node_relationship_info.node_id]\n",
    "    print_python(next_node.text)\n",
    "    node_id = next_node.node_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the children of this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.schema import NodeRelationship\n",
    "\n",
    "def recur_children(node_id):\n",
    "    next_node_relationship_info = split_nodes_by_id[node_id].relationships[\n",
    "        NodeRelationship.CHILD\n",
    "    ]\n",
    "    for children in next_node_relationship_info:\n",
    "        if NodeRelationship.CHILD in split_nodes_by_id[children.node_id].relationships:\n",
    "            next_node = split_nodes_by_id[children.node_id]\n",
    "            print_python(next_node.text)\n",
    "            recur_children(next_node.node_id)\n",
    "            break\n",
    "\n",
    "recur_children(uuid_from_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices\n",
    "\n",
    "Lets explore the use of this node parser in an index. We will be able to use any index which allows search by keyword, which should enable us to search for any node by it's uuid, or by any scope name.\n",
    "\n",
    "Lets use a keyword index to facilitate this kind of operation. We have created a CodeHierarchyKeywordTableIndex which will allow us to search for nodes by their uuid, or by their scope name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n******\nCould not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nTo disable the LLM entirely, set llm=None.\n******",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/llms/utils.py:29\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm)\u001b[0m\n\u001b[1;32m     28\u001b[0m     llm \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mvalidate_openai_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/llms/openai_utils.py:383\u001b[0m, in \u001b[0;36mvalidate_openai_api_key\u001b[0;34m(api_key)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(MISSING_API_KEY_ERROR_MESSAGE)\n",
      "\u001b[0;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_hierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     CodeHierarchyKeywordTableIndex,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeyword_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeywordTableRetrieverMode\n\u001b[0;32m----> 6\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mCodeHierarchyKeywordTableIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m retriever \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mas_retriever(retriever_mode\u001b[38;5;241m=\u001b[39mKeywordTableRetrieverMode\u001b[38;5;241m.\u001b[39mSIMPLE)\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/indices/keyword_table/base.py:85\u001b[0m, in \u001b[0;36mBaseKeywordTableIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, service_context, keyword_extract_template, max_keywords_per_chunk, use_async, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyword_extract_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyword_extract_template\u001b[38;5;241m.\u001b[39mpartial_format(\n\u001b[1;32m     82\u001b[0m     max_keywords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_keywords_per_chunk\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_async \u001b[38;5;241m=\u001b[39m use_async\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/indices/base.py:61\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes must be a list of Node objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context \u001b[38;5;241m=\u001b[39m service_context \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mServiceContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context \u001b[38;5;241m=\u001b[39m storage_context \u001b[38;5;129;01mor\u001b[39;00m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mdocstore\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/service_context.py:178\u001b[0m, in \u001b[0;36mServiceContext.from_defaults\u001b[0;34m(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, text_splitter, transformations, llama_logger, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm_predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLMPredictor is deprecated, please use LLM instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m llm_predictor \u001b[38;5;241m=\u001b[39m llm_predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mLLMPredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpydantic_program_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpydantic_program_mode\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_predictor, LLMPredictor):\n\u001b[1;32m    182\u001b[0m     llm_predictor\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/llm_predictor/base.py:109\u001b[0m, in \u001b[0;36mLLMPredictor.__init__\u001b[0;34m(self, llm, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    102\u001b[0m     llm: Optional[LLMType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     pydantic_program_mode: PydanticProgramMode \u001b[38;5;241m=\u001b[39m PydanticProgramMode\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[1;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback_manager:\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama_index/llms/utils.py:31\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm)\u001b[0m\n\u001b[1;32m     29\u001b[0m         validate_openai_api_key(llm\u001b[38;5;241m.\u001b[39mapi_key)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load OpenAI model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you intended to use OpenAI, please check your OPENAI_API_KEY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo disable the LLM entirely, set llm=None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     42\u001b[0m     splits \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: \n******\nCould not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nTo disable the LLM entirely, set llm=None.\n******"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.code_hierarchy import (\n",
    "    CodeHierarchyKeywordTableIndex,\n",
    ")\n",
    "from llama_index.indices.keyword_table.base import KeywordTableRetrieverMode\n",
    "\n",
    "idx = CodeHierarchyKeywordTableIndex(\n",
    "    nodes=split_nodes,\n",
    ")\n",
    "retriever = idx.as_retriever(retriever_mode=KeywordTableRetrieverMode.SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the same code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('class SentenceWindowNodeParser(NodeParser):\\n'\n",
      " '    # Code replaced for brevity. See node_id '\n",
      " 'fe68e6de-3851-4c77-8acb-445fe45fee6c')\n"
     ]
    }
   ],
   "source": [
    "pprint(retriever.retrieve(uuid_from_text)[0].node.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what about getting the rest of the code for this scope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Code replaced for brevity. See node_id '\n",
      " 'd8a4b50c-c0d9-4338-870a-1ab058d1e3c8\\n'\n",
      " '@classmethod\\n'\n",
      " '    def from_defaults(\\n'\n",
      " '        cls,\\n'\n",
      " '        sentence_splitter: Optional[Callable[[str], List[str]]] = None,\\n'\n",
      " '        window_size: int = DEFAULT_WINDOW_SIZE,\\n'\n",
      " '        window_metadata_key: str = DEFAULT_WINDOW_METADATA_KEY,\\n'\n",
      " '        original_text_metadata_key: str = DEFAULT_OG_TEXT_METADATA_KEY,\\n'\n",
      " '        include_metadata: bool = True,\\n'\n",
      " '        include_prev_next_rel: bool = True,\\n'\n",
      " '        callback_manager: Optional[CallbackManager] = None,\\n'\n",
      " '        metadata_extractor: Optional[MetadataExtractor] = None,\\n'\n",
      " '    ) -> \"SentenceWindowNodeParser\":\\n'\n",
      " '        # Code replaced for brevity. See node_id '\n",
      " 'ecb65036-88bb-4008-806e-b9c629f7d038\\n'\n",
      " '\\n'\n",
      " '    def get_nodes_from_documents(\\n'\n",
      " '        self,\\n'\n",
      " '        documents: Sequence[Document],\\n'\n",
      " '        show_progress: bool = False,\\n'\n",
      " '    ) -> List[BaseNode]:\\n'\n",
      " '        # Code replaced for brevity. See node_id '\n",
      " '85b35f34-2e7c-43ea-add4-25704ceaf129\\n'\n",
      " '\\n'\n",
      " '    def build_window_nodes_from_documents(\\n'\n",
      " '        self, documents: Sequence[Document]\\n'\n",
      " '    ) -> List[BaseNode]:\\n'\n",
      " '        # Code replaced for brevity. See node_id '\n",
      " '02c7f75f-3d88-4cf2-90d1-b7194a2ce7b5',\n",
      " 'class SentenceWindowNodeParser(NodeParser):\\n'\n",
      " '    # Code replaced for brevity. See node_id '\n",
      " 'fe68e6de-3851-4c77-8acb-445fe45fee6c',\n",
      " '# Code replaced for brevity. See node_id '\n",
      " 'aa2137f3-c798-4d55-82c9-5c3e9be1c770\\n'\n",
      " '\"\"\"Sentence window node parser.\\n'\n",
      " '\\n'\n",
      " '    Splits a document into Nodes, with each node being a sentence.\\n'\n",
      " '    Each node contains a window from the surrounding sentences in the '\n",
      " 'metadata.\\n'\n",
      " '\\n'\n",
      " '    Args:\\n'\n",
      " '        sentence_splitter (Optional[Callable]): splits text into sentences\\n'\n",
      " '        include_metadata (bool): whether to include metadata in nodes\\n'\n",
      " '        include_prev_next_rel (bool): whether to include prev/next '\n",
      " 'relationships\\n'\n",
      " '    \"\"\"\\n'\n",
      " '\\n'\n",
      " '    sentence_splitter: Callable[[str], List[str]] = Field(\\n'\n",
      " '        default_factory=split_by_sentence_tokenizer,\\n'\n",
      " '        description=\"The text splitter to use when splitting documents.\",\\n'\n",
      " '        exclude=True,\\n'\n",
      " '    )\\n'\n",
      " '    window_size: int = Field(\\n'\n",
      " '        default=DEFAULT_WINDOW_SIZE,\\n'\n",
      " '        description=\"The number of sentences on each side of a sentence to '\n",
      " 'capture.\",\\n'\n",
      " '    )\\n'\n",
      " '    window_metadata_key: str = Field(\\n'\n",
      " '        default=DEFAULT_WINDOW_METADATA_KEY,\\n'\n",
      " '        description=\"The metadata key to store the sentence window under.\",\\n'\n",
      " '    )\\n'\n",
      " '    original_text_metadata_key: str = Field(\\n'\n",
      " '        default=DEFAULT_OG_TEXT_METADATA_KEY,\\n'\n",
      " '        description=\"The metadata key to store the original sentence in.\",\\n'\n",
      " '    )\\n'\n",
      " '    include_metadata: bool = Field(\\n'\n",
      " '        default=True, description=\"Whether or not to consider metadata when '\n",
      " 'splitting.\"\\n'\n",
      " '    )\\n'\n",
      " '    include_prev_next_rel: bool = Field(\\n'\n",
      " '        default=True, description=\"Include prev/next node relationships.\"\\n'\n",
      " '    )\\n'\n",
      " '    # Code replaced for brevity. See node_id '\n",
      " 'd8a4b50c-c0d9-4338-870a-1ab058d1e3c8',\n",
      " '# Code replaced for brevity. See node_id '\n",
      " 'fe68e6de-3851-4c77-8acb-445fe45fee6c\\n'\n",
      " 'metadata_extractor: Optional[MetadataExtractor] = Field(\\n'\n",
      " '        default=None, description=\"Metadata extraction pipeline to apply to '\n",
      " 'nodes.\"\\n'\n",
      " '    )\\n'\n",
      " '    callback_manager: CallbackManager = Field(\\n'\n",
      " '        default_factory=CallbackManager, exclude=True\\n'\n",
      " '    )\\n'\n",
      " '\\n'\n",
      " '    def __init__(\\n'\n",
      " '        self,\\n'\n",
      " '        sentence_splitter: Optional[Callable[[str], List[str]]] = None,\\n'\n",
      " '        window_size: int = DEFAULT_WINDOW_SIZE,\\n'\n",
      " '        window_metadata_key: str = DEFAULT_WINDOW_METADATA_KEY,\\n'\n",
      " '        original_text_metadata_key: str = DEFAULT_OG_TEXT_METADATA_KEY,\\n'\n",
      " '        include_metadata: bool = True,\\n'\n",
      " '        include_prev_next_rel: bool = True,\\n'\n",
      " '        callback_manager: Optional[CallbackManager] = None,\\n'\n",
      " '        metadata_extractor: Optional[MetadataExtractor] = None,\\n'\n",
      " '    ) -> None:\\n'\n",
      " '        # Code replaced for brevity. See node_id '\n",
      " 'f7a12758-eab1-4cfc-88df-70c3e3d9cd57\\n'\n",
      " '\\n'\n",
      " '    @classmethod\\n'\n",
      " '    def class_name(cls) -> str:\\n'\n",
      " '        return \"SentenceWindowNodeParser\"\\n'\n",
      " '\\n'\n",
      " '    @property\\n'\n",
      " '    def text_splitter(self) -> Callable[[str], List[str]]:\\n'\n",
      " '        # Code replaced for brevity. See node_id '\n",
      " '306070f6-3762-464a-a25e-3648db2a87fa\\n'\n",
      " '    # Code replaced for brevity. See node_id '\n",
      " 'cf88a5bb-8bcd-46c2-9169-4f6e82b12b78']\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    [\n",
    "        n.node.get_content()\n",
    "        for n in retriever.retrieve(\"SentenceWindowNodeParser\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difficulty is that these are out of order. The CodeSplitter controls how much overlap there is for each of these documents, and how big they are. You can play with its settings to disambiguate any confusion. However, they do have their uuids for their splits in the text themselves, so an LLM should be able to recursively search these documents to put them in some kind of order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy\n",
    "\n",
    "The namesake of this node parser, creates a tree of scope names to use to search the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ..\n",
      "  - ..\n",
      "    - ..\n",
      "      - ..\n",
      "        - llama_index\n",
      "          - node_parser\n",
      "            - sentence_window.py\n",
      "              - SentenceWindowNodeParser\n",
      "                - __init__\n",
      "                - text_splitter\n",
      "                - from_defaults\n",
      "                - get_nodes_from_documents\n",
      "                - build_window_nodes_from_documents\n",
      "            - code_hierarchy.py\n",
      "              - _SignatureCaptureType\n",
      "              - _SignatureCaptureOptions\n",
      "              - _ScopeMethod\n",
      "              - _CommentOptions\n",
      "              - _ScopeItem\n",
      "              - _ChunkNodeOutput\n",
      "              - CodeHierarchyNodeParser\n",
      "                - class_name\n",
      "                - __init__\n",
      "                - _get_node_name\n",
      "                  - recur\n",
      "                - _get_node_signature\n",
      "                  - find_start\n",
      "                  - find_end\n",
      "                - _chunk_node\n",
      "                - get_code_hierarchy_from_nodes\n",
      "                  - get_subdict\n",
      "                  - recur_inclusive_scope\n",
      "                  - dict_to_markdown\n",
      "                - get_nodes_from_documents\n",
      "                - _get_indentation\n",
      "                - _get_comment_text\n",
      "                - _create_comment_line\n",
      "                - _get_replacement_text\n",
      "                - _skeletonize\n",
      "                - _skeletonize_list\n",
      "                  - recur\n",
      "            - loading.py\n",
      "              - load_parser\n",
      "            - node_utils.py\n",
      "              - build_nodes_from_splits\n",
      "              - get_nodes_from_document\n",
      "              - get_nodes_from_node\n",
      "            - unstructured_element.py\n",
      "              - TableColumnOutput\n",
      "                - __str__\n",
      "              - TableOutput\n",
      "              - Element\n",
      "              - html_to_df\n",
      "              - filter_table\n",
      "              - extract_elements\n",
      "              - extract_table_summaries\n",
      "              - get_table_elements\n",
      "              - get_text_elements\n",
      "              - _get_nodes_from_buffer\n",
      "              - get_nodes_from_elements\n",
      "              - UnstructuredElementNodeParser\n",
      "                - __init__\n",
      "                - from_defaults\n",
      "                - get_nodes_from_node\n",
      "                - get_nodes_from_documents\n",
      "                - get_base_nodes_and_mappings\n",
      "            - hierarchical.py\n",
      "              - _add_parent_child_relationship\n",
      "              - get_leaf_nodes\n",
      "              - get_root_nodes\n",
      "              - HierarchicalNodeParser\n",
      "                - from_defaults\n",
      "                - _recursively_get_nodes_from_nodes\n",
      "                - get_nodes_from_documents\n",
      "            - simple_file.py\n",
      "              - SimpleFileNodeParser\n",
      "                - from_defaults\n",
      "                - class_name\n",
      "                - get_nodes_from_documents\n",
      "            - interface.py\n",
      "              - NodeParser\n",
      "                - get_nodes_from_documents\n",
      "              - BaseExtractor\n",
      "                - extract\n",
      "            - simple.py\n",
      "              - SimpleNodeParser\n",
      "                - from_defaults\n",
      "                - get_nodes_from_documents\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CodeHierarchyNodeParser.get_code_hierarchy_from_nodes(split_nodes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
