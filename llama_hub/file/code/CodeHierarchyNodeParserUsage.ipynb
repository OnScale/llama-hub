{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy Node Parser\n",
    "\n",
    "The `CodeHierarchyNodeParser` is useful to split long code files into more reasonable chunks. What this will do is create a \"Hierarchy\" of sorts, where sections of the code are made more reasonable by replacing the scope body with short comments telling the LLM to search for a referenced node if it wants to read that context body. This is called skeletonization, and is toggled by setting `skeleton` to `True` which it is by default. Nodes in this hierarchy will be split based on scope, like function, class, or method scope, and will have links to their children and parents so the LLM can traverse the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Import\n",
    "\n",
    "First be sure to install the necessary [tree-sitter](https://tree-sitter.github.io/tree-sitter/) libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tree-sitter in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_hub/lib/python3.10/site-packages (0.20.4)\n",
      "Requirement already satisfied: tree-sitter-languages in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_hub/lib/python3.10/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tree-sitter tree-sitter-languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_hierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeHierarchyNodeParser\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeSplitter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_hub'"
     ]
    }
   ],
   "source": [
    "from llama_hub.file.code.code_hierarchy import CodeHierarchyNodeParser\n",
    "from llama_index.text_splitter import CodeSplitter\n",
    "from llama_index.readers import SimpleDirectoryReader\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def print_python(python_text):\n",
    "    \"\"\"This function prints python text in ipynb nicely formatted.\"\"\"\n",
    "    display(Markdown(\"```python\\n\"+python_text+\"```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a directory you want to scan, and glob for all the code files you want to import.\n",
    "\n",
    "In this case I'm going to glob all \"*.py\" files in the `llama_index/node_parser` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[Path(\"./code_hierarchy.py\")],\n",
    "    file_metadata=lambda x: {\"filepath\": x},\n",
    ")\n",
    "nodes = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the code hierarchy node parser itself. Lets have it parse itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 33247\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    start_signature_types: Optional[List[_SignatureCaptureType]] = Field(\n",
       "\n",
       "# ...```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Length of text: {len(nodes[0].text)}\")\n",
    "print_python(nodes[0].text[:1500]+\"\\n\\n# ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is way too long to fit into the context of our LLM. So what are we to do? Well we will split it. We are going to use the `CodeHierarchyNodeParser` to split the nodes into more reasonable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes after splitting: 87\n"
     ]
    }
   ],
   "source": [
    "split_nodes = CodeHierarchyNodeParser(\n",
    "    language=\"python\",\n",
    "    # You can further parameterize the CodeSplitter to split the code\n",
    "    # into \"chunks\" that match your context window size using\n",
    "    # chunck_lines and max_chars parameters, here we just use the defaults\n",
    "    code_splitter=CodeSplitter(language=\"python\", max_chars=1000, chunk_lines=10),\n",
    ").get_nodes_from_documents(nodes)\n",
    "print(\"Number of nodes after splitting:\", len(split_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So that split up our data from 1 node into 86 nodes! Whats the max length of any of these nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest text in nodes: 1160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longest text in nodes: {max(len(n.text) for n in split_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much shorter than before! Let's look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(split_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without even needing a long printout we can see everything this module imported in the first document (which is at the module level) and some classes it defines.\n",
    "\n",
    "We also see that it has put comments in place of code that was removed to make the text size more reasonable.\n",
    "These can appear at the beginning or end of a chunk, or at a new scope level, like a class or function declaration.\n",
    "\n",
    "`# Code replaced for brevity. See node_id {node_id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy\n",
    "\n",
    "These scopes can be listed by the `CodeHierarchyNodeParser`, giving a \"repo map\" of sorts.\n",
    "The namesake of this node parser, it creates a tree of scope names to use to search the code.\n",
    "Put this in your context to give the LLM a default search hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruct an LLM using the KeywordQueryEngine (shown later) as a tool to:\n",
    "\n",
    "```\n",
    "\"Search the tool by any element in this list, or any uuid found in the resulting code, to get more information about that element.\"\n",
    "```\n",
    "\n",
    "Then append this to your context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- code_hierarchy\n",
      "  - _SignatureCaptureType\n",
      "  - _SignatureCaptureOptions\n",
      "  - _ScopeMethod\n",
      "  - _CommentOptions\n",
      "  - _ScopeItem\n",
      "  - _ChunkNodeOutput\n",
      "  - CodeHierarchyNodeParser\n",
      "    - class_name\n",
      "    - __init__\n",
      "    - _get_node_name\n",
      "      - recur\n",
      "    - _get_node_signature\n",
      "      - find_start\n",
      "      - find_end\n",
      "    - _chunk_node\n",
      "    - get_code_hierarchy_from_nodes\n",
      "      - get_subdict\n",
      "      - recur_inclusive_scope\n",
      "      - dict_to_markdown\n",
      "    - _parse_nodes\n",
      "    - _get_indentation\n",
      "    - _get_comment_text\n",
      "    - _create_comment_line\n",
      "    - _get_replacement_text\n",
      "    - _skeletonize\n",
      "    - _skeletonize_list\n",
      "      - recur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CodeHierarchyNodeParser.get_code_hierarchy_from_nodes(split_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration by the Programmer\n",
    "\n",
    "So that we understand what is going on under the hood, what if we go to that node_id we found above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to print the node with UUID: 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1165ccf1-7954-4350-847e-8677ae49a5a0\n",
       "\"\"\"\n",
       "Maps language -> Node Type -> SignatureCaptureOptions\n",
       "\n",
       "The best way for a developer to discover these is to put a breakpoint at the TIP\n",
       "tag in _chunk_node, and then create a unit test for some code, and then iterate\n",
       "through the code discovering the node names.\n",
       "\"\"\"\n",
       "    # Code replaced for brevity. See node_id 13c351a9-fa3c-4d91-8e4a-bfde2b7d4f6c```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_nodes_by_id = {n.node_id: n for n in split_nodes}\n",
    "uuid_from_text = split_nodes[0].text.splitlines()[-1].split(\" \")[-1]\n",
    "print(\"Going to print the node with UUID:\", uuid_from_text)\n",
    "print_python(split_nodes_by_id[uuid_from_text].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the next split in the file. It is prepended with the node before it and appended with the node after it as a comment.\n",
    "\n",
    "We can also see the relationships on this node programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1165ccf1-7954-4350-847e-8677ae49a5a0\n",
       "\"\"\"\n",
       "Maps language -> Node Type -> SignatureCaptureOptions\n",
       "\n",
       "The best way for a developer to discover these is to put a breakpoint at the TIP\n",
       "tag in _chunk_node, and then create a unit test for some code, and then iterate\n",
       "through the code discovering the node names.\n",
       "\"\"\"\n",
       "    # Code replaced for brevity. See node_id 13c351a9-fa3c-4d91-8e4a-bfde2b7d4f6c```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(split_nodes_by_id[uuid_from_text].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NEXT` `PREV` relationships come from the `CodeSplitter` which is a component of the `CodeHierarchyNodeParser`. It is responsible for cutting up the nodes into chunks that are a certain character length. For more information about the `CodeSplitter` read this:\n",
    "\n",
    "[Code Splitter](https://docs.llamaindex.ai/en/latest/api/llama_index.node_parser.CodeSplitter.html)\n",
    "\n",
    "The `PARENT` and `CHILD` relationships come from the `CodeHierarchyNodeParser` which is responsible for creating the hierarchy of nodes. Things like classes, functions, and methods are nodes in this hierarchy.\n",
    "\n",
    "The `SOURCE` is the original file that this node came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311\n",
       "_DEFAULT_SIGNATURE_IDENTIFIERS: Dict[str, Dict[str, _SignatureCaptureOptions]] =\n",
       "    # Code replaced for brevity. See node_id 04a96f73-8399-4ec6-8db7-ae18cd18127d```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.schema import NodeRelationship\n",
    "\n",
    "node_id = uuid_from_text\n",
    "if NodeRelationship.NEXT not in split_nodes_by_id[node_id].relationships:\n",
    "    print(\"No next node found!\")\n",
    "else:\n",
    "    next_node_relationship_info = split_nodes_by_id[node_id].relationships[\n",
    "        NodeRelationship.NEXT\n",
    "    ]\n",
    "    next_node = split_nodes_by_id[next_node_relationship_info.node_id]\n",
    "    print_python(next_node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Table and Usage by the LLM\n",
    "\n",
    "Lets explore the use of this node parser in an index. We will be able to use any index which allows search by keyword, which should enable us to search for any node by it's uuid, or by any scope name.\n",
    "\n",
    "We have created a `CodeHierarchyKeywordQueryEngine` which will allow us to search for nodes by their uuid, or by their scope name. It's `.query` method can be used as a simple search tool for any LLM. Given the repo map we created earlier, or the text of a split file, the LLM should be able to figure out what to search for very naturally.\n",
    "\n",
    "Lets create the KeywordQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index import CodeHierarchyKeywordQueryEngine\n",
    "\n",
    "idx = CodeHierarchyKeywordQueryEngine(\n",
    "    nodes=split_nodes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the same code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(split_nodes[0].node_id).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we can also search for any node by it's common sense name.\n",
    "\n",
    "For example, the class `_SignatureCaptureOptions` is a node in the hierarchy. We can search for it by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(\"_SignatureCaptureType\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by module name, in case the LLM sees something in an import statement and wants to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(\"code_hierarchy\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As a Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the langchain tool, just use `as_langchain_tool` on the `CodeHierarchyKeywordQueryEngine` and it will be ready to use in the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.as_langchain_tool().run(\"code_hierarchy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description for your LLM to read to learn the tool is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Code Search\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Description: \n",
       "        Search the tool by any element in this list,\n",
       "        or any uuid found in the code,\n",
       "        to get more information about that element.\n",
       "\n",
       "        - code_hierarchy\n",
       "  - _SignatureCaptureType\n",
       "  - _SignatureCaptureOptions\n",
       "  - _ScopeMethod\n",
       "  - _CommentOptions\n",
       "  - _ScopeItem\n",
       "  - _ChunkNodeOutput\n",
       "  - CodeHierarchyNodeParser\n",
       "    - class_name\n",
       "    - __init__\n",
       "    - _get_node_name\n",
       "      - recur\n",
       "    - _get_node_signature\n",
       "      - find_start\n",
       "      - find_end\n",
       "    - _chunk_node\n",
       "    - get_code_hierarchy_from_nodes\n",
       "      - get_subdict\n",
       "      - recur_inclusive_scope\n",
       "      - dict_to_markdown\n",
       "    - _parse_nodes\n",
       "    - _get_indentation\n",
       "    - _get_comment_text\n",
       "    - _create_comment_line\n",
       "    - _get_replacement_text\n",
       "    - _skeletonize\n",
       "    - _skeletonize_list\n",
       "      - recur\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Name: \"+idx.as_langchain_tool().name)\n",
    "display(Markdown(\"Description: \"+idx.as_langchain_tool().description))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
